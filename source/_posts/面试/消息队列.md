---
title: 消息队列多连炮
date: 2020-12-16
categories:
    - 面试
tags:
    - 消息队列
---

#### 为什么使用消息队列？ 
* 解耦
* 异步
* 消峰

#### 消息队列有什么优点和缺点？ 
* 系统可用性降低
* 系统复杂性变高
* 一致性问题

#### kafka、activemq、rabbitmq、rocketmq 都有什么区别以及适合的场景？

| 特性	                       | ActiveMQ      | RabbitMQ  | RocketMQ  |Kafka  |
| ---------------------------- |:-------------:| :-----:|:-----:|:-----:|
| 单机吞吐量                   | 万级          | 万级  |  10 万级，支撑高吞吐  | 10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景 |
| topic 数量对吞吐量的影响     |       |    | topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic | topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源 |
| 时效性                       | ms 级     | 微秒级，延迟最低 | ms 级 | ms 级 |
| 可用性	                   | 高，基于主从架构实现高可用 | 同 ActiveMQ | 非常高，分布式架构 | 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 |
| 消息可靠性	               | 有较低的概率丢失数据 | 基本不丢 | 经过参数优化配置，可以做到 0 丢失 | 同 RocketMQ |
| 功能支持	                   | MQ 领域的功能极其完备 | 基于erlang 开发，并发能力很强，性能极好，延时很低 | MQ 功能较为完善，还是分布式的，扩展性好 | 功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用 |


综上，各种对比之后，有如下建议：

> 一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了；
> 后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高；
> 不过现在确实越来越多的公司，会去用 RocketMQ，确实很不错（阿里出品），但社区可能有突然黄掉的风险，对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。
> 所以中小型公司，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；大型公司，基础架构研发实力较强，用 RocketMQ 是很好的选择。
> 如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范


#### 如何保证消息队列的高可用

##### RabbitMQ 的高可用性
* 单机模式
* 普通集群模式（无高可用性）
    * 消费者每次随机连接一个实例，然后该实例从真正的数据节点拉取数据，有数据拉取的开销
    * 固定连接那个 queue 所在实例消费数据，导致单实例性能瓶颈
    * 不是分布式的
* 镜像集群模式（高可用性）
    * 不是分布式的，每个节点都有这个queue的完整数据，如果queue的数据量很大，大到这个机器上的容量无法容纳就会有问题
##### Kafka 的高可用架构

* 分布式集群模式
    * kafka 是由多个 broker 组成，每个 broker 是一个节点
    * 创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上
    * 每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本
    * 所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其他 replica 就是 follower
    * leader 会负责把数据同步到所有 follower 上去，读/写的时候就直接读/写 leader 上的数据即可
    * 如果某个 broker 宕机了并且 broker上面有某个 partition 的 leader，那么此时会从其他broker的 follower 中重新选举一个新的 leader 出来，大家继续读写那个新的 leader 即可

写数据的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为）

消费的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到

#### 如何解决消息的重复消费

主要结合业务来实现消息的幂等性
* 数据的主键ID,不存在插入，存在则更新
* 用redis给消息标记，存在则不处理

#### 如何保证消息的可靠性（如何处理消息丢失问题）

##### RabbitMQ 
1. 写消息的过程中消息都没有到rabbitMq，或者消息到rabbitMq但是人家内部出错没有保存下来
    * 事务模式 （同步）
    * confirm模式（回调方法确认消息接收成功）（异步）
2. rabbitMq接收到消息之后暂存到自己的内存里，在消费之前出现故障、重启导致内存数据丢失
    * 将消息持久化到磁盘上（同时持久化queue 和消息的持久化）
3. 消费者消费到了消息，但是还没来及处理就挂掉了，rabbitMq以为这个消费者已经处理完了
    * 将autoAck关闭，如果消费者没处理完就宕机了，此时rabbitMq没有收到你的ack消息，就会将这条消息重新分配给其他的消费者处理
    
##### Kafka
1. 消费者消费到了消息，但是还没来及处理就挂掉了，kafak以为这个消费者已经处理完了
    * 关闭自动提交offset，此时有重复消费的问题，自己保证幂等性
2. kafka 某个broker宕机，然后重新选举partition的leader，而之前的leader还没有来的及同步数据到follower中
    * topic的 **replication.factor** 参数的值必须大于1，即每个partition至少有2个副本
    * kafka的服务端设置 min.insync.replicas 参数的值必须大于1，即要求一个leader至少感知到一个follower还跟自己保持联系
    * 在producer端设置 acks=all，这个是要求每条数据必须写入所有replica之后，才能认为是写入成功
    * 在producer端设置 retries=MAX(很大的一个值，无限重试的意思)，这个是要求一旦写入失败，重试写入的次数
    
#### 如何保证消息的顺序性

##### RabbitMQ
1. 一个queue，多个consumer消费速度不一样，导致消费顺序不一致
    * 拆分多个queue，每个queue对应一个consumer
    * 一个queue对应一个consumer，然后内部用内存队列做排列，然后再分发给不同的worker来处理
##### Kafka
1. 一个topic,一个partition，一个consumer，内部多线程
    * 内部单线程消费，根据唯一标识hash 写入N个内存queue，然后N个线程分别消费一个内存queue即可
    
#### 有几百万消息持续积压几个小时怎么处理？
1. 先修复consumer的问题，确保其恢复消费速度，然后将现有consumer都停掉
2. 新建一个topic，partition是原来的10倍，临时建立好原来10倍的queue数量
3. 然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消耗之后不做耗时的处理，直接均匀的轮询写入建立好的10倍数量的queue
4. 接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时的queue的数据
5. 这种做法就相当于是临时将queue资源和consumer资源扩大10倍，以正常的10速度消费数据
6. 等快速消费完积压数据以后，恢复原来的部署架构，重新用原来的consumer机器来消费消息

#### 如何解决消息队列的延时以及过期失效的问题？ 
假设你用的是rabbitMq，刚好你设置了过期时间TTL,如果消息在queue中积压超过一定的时间就会被rabbitMq给清理掉，这个数据就没了

**这个时候就需要些一个临时的程序把丢失的数据查出来，然后重新的插入到mq里面去，然后执行业务代码补全数据**

#### 消息队列满了以后怎么处理？ 就是MQ积压的快挂掉了
* 数据不重要
    * 临时写程序快速消费消息，消费一个丢弃一个，然后到了晚上再补数据
* 数据重要
    * 临时写程序快速写入另外一个消息队列，然后再增加10倍queue、consumer来消费数据

#### 如果让你来开发一个消息中间件，你会如何设计架构
* **首先这个mq要支持可伸缩性，即快速的扩容增加吞吐量和容量**
    * 参考kafka的设计理念，broker->topic->partition
    * 每个partition在一个机器中就存放一部分数据
    * 需要扩容的时候，就给topic增加partition，然后做数据迁移，增加机器就可以存放更多的数据，提高吞吐量
* **mq数据要落磁盘，避免重启丢、故障失数据**
    * 顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是kafka的思路
* **mq的可用性**
    * kafka高可用机制，多副本->leader & follower ->broker  挂了重新选举leader即可对外服务
* **支持数据0丢失**
    * 参考kafka 零丢失配置方案